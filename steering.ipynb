{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = [[0, 10], [1, 9], [2, 9], [3, 10], [4, 9], [5, 10], [6, 9], [7, 9], [8, 10], [9, 10], [10, 11], [11, 10], [12, 10], [13, 11],[14, 11], [15, 11], [16, 10], [17, 10], [18, 9], [19, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0, 5.0], [7.5, 7.5], [10.5, 10.5]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "blank = cv2.imread(\"blank.png\",0)\n",
    "blank = cv2.resize(blank,(20,20))\n",
    "# path = np.array(path)\n",
    "# epsilon = 0.1*cv2.arcLength(path, True)\n",
    "# path = cv2.approxPolyDP(path, epsilon, False)\n",
    "# print(path)\n",
    "pnts = []\n",
    "for i in range(1,16):\n",
    "    pts = [np.mean(path[0:15*(i)][0]),np.mean(path[0:15*(i)][1])]\n",
    "    pnts.append(pts)\n",
    "#     cv2.line(blank,(path[i][1],path[i][0]),(path[i+1][1],path[i+1][0]),0)\n",
    "#     pnts = np.mean(path[i:i+15][0])\n",
    "print(pnts)\n",
    "blank = cv2.resize(blank,(680,480))\n",
    "cv2.imshow(\"blank\",blank)\n",
    "q = cv2.waitKey(1)\n",
    "if q == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "slp = []\n",
    "for pix in pnts:\n",
    "    slp.append(math.atan2(340-pix[1],pix[0]-240) - 1.57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1292184306130484, 0.0007963267948964958]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(slp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output:: 6 category  \n",
    "#input:: 15 slope \n",
    "#mode = xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.state_size = 15\n",
    "        self.action_size = 6\n",
    "        self.memry = deque(maxlen=pow(10,6))\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.bst = xgb.Booster({'nthread':4})\n",
    "        self.name = 'steerDeepQL'\n",
    "        self.modelname = 'xgbmodel'\n",
    "    \n",
    "    def xgbmodel_bld(self,data,label):\n",
    "        param = {'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'multi:softprob','num_class': 6}  \n",
    "        param['nthread'] = 4\n",
    "        num_round = 2000  \n",
    "        dtrain = xgb.DMatrix(data, label=label)\n",
    "        self.bst = xgb.train(param, dtrain, num_round, xgb_model = name)\n",
    "        self.save_bst(name)\n",
    "        \n",
    "    def load_bst():\n",
    "        booster = bst.load_model(name)\n",
    "        return booster\n",
    "    \n",
    "    def save_bst():\n",
    "        bst.save_model(name)\n",
    "        \n",
    "    def act(state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.bst.predict(state)\n",
    "        return np.argmax(act_values[0])         \n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = self.memory\n",
    "        self.memory.clear()\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.bst.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "        self.xgbmodel_bld(state, target)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def decl_rew(self,state):\n",
    "        rew = np.sum((np.array([1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75]) - abs(state))*np.array([10,10,10,9,9,9,8,8,7,6,5,4,3,2,1]))\n",
    "        d = False\n",
    "        if rew > 130:\n",
    "            d = True\n",
    "        return [rew, True]\n",
    "\n",
    "    \n",
    "    def get_nextstate():\n",
    "        ########\n",
    "        stt = np.zeros((1,15),ndtype = 'float')\n",
    "        return stt\n",
    "    \n",
    "def steer(GameOn):\n",
    "    state_size = 15\n",
    "    action_size = 6\n",
    "    agent = DQNAgent()\n",
    "    batch_size = 50\n",
    "    state = np.zeros((1,15),ndtype = 'float')\n",
    "    state = get_nextstate()\n",
    "    agent.load_bst()\n",
    "    \n",
    "    while GameOn:\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        action = agent.act(state)\n",
    "        print(\"action:\",action)\n",
    "        execute_action(action)\n",
    "        reward, done = decl_rew(state)\n",
    "        reward = reward if not done else -10\n",
    "        next_state = get_nextstate()\n",
    "        if(next_state == []):\n",
    "            continue;\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"updating weights under 10 deg\")\n",
    "            agent.update_target_model()\n",
    "        if len(agent.memory) >= 1500:\n",
    "            print(\"replaying at {} xgboost\".fromat(len(agent.memory)))\n",
    "            agent.replay(batch_size)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "EPISODES = 500\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=pow(10,6))\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "        \n",
    "    \n",
    "    def _build_model(self):\n",
    "        param = { 'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'multi:softprob','num_class': 6}  \n",
    "        num_round = 2000  \n",
    "        classifier = xgb.sklearn.XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "                       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "                        min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "                       objective='multi:softmax', reg_alpha=0, reg_lambda=1,\n",
    "                       scale_pos_weight=1, seed=42, silent=True, subsample=1)\n",
    "        return classifier\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_model(self.model.save_model())\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0]) \n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "#         eval_set = [(X_test, y_test)]\n",
    "        self.model.fit(state, target,eval_metric=\"error\", eval_set=eval_set, verbose=True)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_model(name)\n",
    "    \n",
    "    def save(self, name):\n",
    "        self.model.save_model(name)\n",
    "    \n",
    "    def decl_rew(self,state):\n",
    "        rew = np.sum((np.array([1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75,1.75]) - abs(state))*np.array([10,10,10,9,9,9,8,8,7,6,5,4,3,2,1]))\n",
    "        d = False\n",
    "        if rew > 130:\n",
    "            d = True\n",
    "        return [nxtstate, rew, True]\n",
    "        \n",
    "\n",
    "\n",
    "def steer():\n",
    "    state_size = 15\n",
    "    action_size = 6\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "    \n",
    "#     agent.load_model(\"./save/steerwts.h5\")\n",
    "    \n",
    "    batch_size = 50\n",
    "    state = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0] \n",
    "    while True:\n",
    "        done = False\n",
    "        while True:\n",
    "            state = np.reshape(state, [1, state_size])\n",
    "            action = agent.act(state)\n",
    "            print(\"action:\",action)\n",
    "            execute_action(action)\n",
    "            next_state, reward, done = decl_rew(state)##input and reward\n",
    "            if(next_state == []):\n",
    "                continue;\n",
    "            reward = reward if not done else -10\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                print(\"updating weights under 10 deg\")\n",
    "                agent.update_target_model()\n",
    "            if len(agent.memory) > batch_size:\n",
    "                print(\"replaying at 50 and saving weights\")\n",
    "                agent.replay(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-b0eaa6878a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msteer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-b91c948ff5f2>\u001b[0m in \u001b[0;36msteer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m#     agent.load_model(\"./save/steerwts.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-b91c948ff5f2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_size, action_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-b91c948ff5f2>\u001b[0m in \u001b[0;36mupdate_target_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_target_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "steer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[-0.02340593 -0.04727202 -0.00067567 -0.02899503]]\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(state_size)\n",
    "state = np.reshape(state, [-1, state_size])\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# agent.save(\"./save/cartpole-ddqn.h5\")\n",
    "print(state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def screen_record(): \n",
    "    last_time = time.time()\n",
    "    while True:\n",
    "        # 800x600 windowed mode\n",
    "        printscreen_pil =  ImageGrab.grab(bbox=(0,40,800,640))\n",
    "        printscreen_numpy =   np.array(printscreen_pil.getdata(),dtype='uint8')\\\n",
    "        .reshape((printscreen_pil.size[1],printscreen_pil.size[0],3))\n",
    "        print('loop took {} seconds'.format(time.time()-last_time))\n",
    "        last_time = time.time()\n",
    "\n",
    "    ##    cv2.imshow('window',cv2.cvtColor(printscreen_numpy, cv2.COLOR_BGR2RGB))\n",
    "    ##    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "    ##        cv2.destroyAllWindows()\n",
    "    ##        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(pow(10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x128832390>\n"
     ]
    }
   ],
   "source": [
    "data = np.random.rand(5,10) # 5 entities, each contains 10 features\n",
    "label = np.random.randint(2, size=5) # binary target\n",
    "dtest = np.random.rand(5,10)\n",
    "dtrain = xgb.DMatrix( data, label=label)\n",
    "print(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'bst:max_depth':2, 'bst:eta':1, 'silent':1, 'objective':'multi:softmax' }\n",
    "param['nthread'] = 4\n",
    "plst = param.items() \n",
    "# plst += [('eval_metric', 'merror')] \n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid cache item: ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-98b1512f6cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevallist\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mnboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mnum_parallel_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, cache, model_file)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid cache item: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid cache item: ndarray"
     ]
    }
   ],
   "source": [
    "num_round = 10\n",
    "\n",
    "bst = xgb.train( plst, dtrain, num_round, evallist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttraining-merror:0\n",
      "[1]\ttraining-merror:0\n",
      "[2]\ttraining-merror:0\n",
      "[3]\ttraining-merror:0\n",
      "[4]\ttraining-merror:0\n",
      "[5]\ttraining-merror:0\n",
      "[6]\ttraining-merror:0\n",
      "[7]\ttraining-merror:0\n",
      "[8]\ttraining-merror:0\n",
      "[9]\ttraining-merror:0\n",
      "[10]\ttraining-merror:0\n",
      "[11]\ttraining-merror:0\n",
      "[12]\ttraining-merror:0\n",
      "[13]\ttraining-merror:0\n",
      "[14]\ttraining-merror:0\n",
      "[15]\ttraining-merror:0\n",
      "[16]\ttraining-merror:0\n",
      "[17]\ttraining-merror:0\n",
      "[18]\ttraining-merror:0\n",
      "[19]\ttraining-merror:0\n",
      "[20]\ttraining-merror:0\n",
      "[21]\ttraining-merror:0\n",
      "[22]\ttraining-merror:0\n",
      "[23]\ttraining-merror:0\n",
      "[24]\ttraining-merror:0\n",
      "[25]\ttraining-merror:0\n",
      "[26]\ttraining-merror:0\n",
      "[27]\ttraining-merror:0\n",
      "[28]\ttraining-merror:0\n",
      "[29]\ttraining-merror:0\n",
      "[30]\ttraining-merror:0\n",
      "[31]\ttraining-merror:0\n",
      "[32]\ttraining-merror:0\n",
      "[33]\ttraining-merror:0\n",
      "[34]\ttraining-merror:0\n",
      "[35]\ttraining-merror:0\n",
      "[36]\ttraining-merror:0\n",
      "[37]\ttraining-merror:0\n",
      "[38]\ttraining-merror:0\n",
      "[39]\ttraining-merror:0\n",
      "[40]\ttraining-merror:0\n",
      "[41]\ttraining-merror:0\n",
      "[42]\ttraining-merror:0\n",
      "[43]\ttraining-merror:0\n",
      "[44]\ttraining-merror:0\n",
      "[45]\ttraining-merror:0\n",
      "[46]\ttraining-merror:0\n",
      "[47]\ttraining-merror:0\n",
      "[48]\ttraining-merror:0\n",
      "[49]\ttraining-merror:0\n",
      "[50]\ttraining-merror:0\n",
      "[51]\ttraining-merror:0\n",
      "[52]\ttraining-merror:0\n",
      "[53]\ttraining-merror:0\n",
      "[54]\ttraining-merror:0\n",
      "[55]\ttraining-merror:0\n",
      "[56]\ttraining-merror:0\n",
      "[57]\ttraining-merror:0\n",
      "[58]\ttraining-merror:0\n",
      "[59]\ttraining-merror:0\n",
      "[60]\ttraining-merror:0\n",
      "[61]\ttraining-merror:0\n",
      "[62]\ttraining-merror:0\n",
      "[63]\ttraining-merror:0\n",
      "[64]\ttraining-merror:0\n",
      "[65]\ttraining-merror:0\n",
      "[66]\ttraining-merror:0\n",
      "[67]\ttraining-merror:0\n",
      "[68]\ttraining-merror:0\n",
      "[69]\ttraining-merror:0\n",
      "[70]\ttraining-merror:0\n",
      "[71]\ttraining-merror:0\n",
      "[72]\ttraining-merror:0\n",
      "[73]\ttraining-merror:0\n",
      "[74]\ttraining-merror:0\n",
      "[75]\ttraining-merror:0\n",
      "[76]\ttraining-merror:0\n",
      "[77]\ttraining-merror:0\n",
      "[78]\ttraining-merror:0\n",
      "[79]\ttraining-merror:0\n",
      "[80]\ttraining-merror:0\n",
      "[81]\ttraining-merror:0\n",
      "[82]\ttraining-merror:0\n",
      "[83]\ttraining-merror:0\n",
      "[84]\ttraining-merror:0\n",
      "[85]\ttraining-merror:0\n",
      "[86]\ttraining-merror:0\n",
      "[87]\ttraining-merror:0\n",
      "[88]\ttraining-merror:0\n",
      "[89]\ttraining-merror:0\n",
      "[90]\ttraining-merror:0\n",
      "[91]\ttraining-merror:0\n",
      "[92]\ttraining-merror:0\n",
      "[93]\ttraining-merror:0\n",
      "[94]\ttraining-merror:0\n",
      "[95]\ttraining-merror:0\n",
      "[96]\ttraining-merror:0\n",
      "[97]\ttraining-merror:0\n",
      "[98]\ttraining-merror:0\n",
      "[99]\ttraining-merror:0\n",
      "[100]\ttraining-merror:0\n",
      "[101]\ttraining-merror:0\n",
      "[102]\ttraining-merror:0\n",
      "[103]\ttraining-merror:0\n",
      "[104]\ttraining-merror:0\n",
      "[105]\ttraining-merror:0\n",
      "[106]\ttraining-merror:0\n",
      "[107]\ttraining-merror:0\n",
      "[108]\ttraining-merror:0\n",
      "[109]\ttraining-merror:0\n",
      "[110]\ttraining-merror:0\n",
      "[111]\ttraining-merror:0\n",
      "[112]\ttraining-merror:0\n",
      "[113]\ttraining-merror:0\n",
      "[114]\ttraining-merror:0\n",
      "[115]\ttraining-merror:0\n",
      "[116]\ttraining-merror:0\n",
      "[117]\ttraining-merror:0\n",
      "[118]\ttraining-merror:0\n",
      "[119]\ttraining-merror:0\n",
      "[120]\ttraining-merror:0\n",
      "[121]\ttraining-merror:0\n",
      "[122]\ttraining-merror:0\n",
      "[123]\ttraining-merror:0\n",
      "[124]\ttraining-merror:0\n",
      "[125]\ttraining-merror:0\n",
      "[126]\ttraining-merror:0\n",
      "[127]\ttraining-merror:0\n",
      "[128]\ttraining-merror:0\n",
      "[129]\ttraining-merror:0\n",
      "[130]\ttraining-merror:0\n",
      "[131]\ttraining-merror:0\n",
      "[132]\ttraining-merror:0\n",
      "[133]\ttraining-merror:0\n",
      "[134]\ttraining-merror:0\n",
      "[135]\ttraining-merror:0\n",
      "[136]\ttraining-merror:0\n",
      "[137]\ttraining-merror:0\n",
      "[138]\ttraining-merror:0\n",
      "[139]\ttraining-merror:0\n",
      "[140]\ttraining-merror:0\n",
      "[141]\ttraining-merror:0\n",
      "[142]\ttraining-merror:0\n",
      "[143]\ttraining-merror:0\n",
      "[144]\ttraining-merror:0\n",
      "[145]\ttraining-merror:0\n",
      "[146]\ttraining-merror:0\n",
      "[147]\ttraining-merror:0\n",
      "[148]\ttraining-merror:0\n",
      "[149]\ttraining-merror:0\n",
      "[150]\ttraining-merror:0\n",
      "[151]\ttraining-merror:0\n",
      "[152]\ttraining-merror:0\n",
      "[153]\ttraining-merror:0\n",
      "[154]\ttraining-merror:0\n",
      "[155]\ttraining-merror:0\n",
      "[156]\ttraining-merror:0\n",
      "[157]\ttraining-merror:0\n",
      "[158]\ttraining-merror:0\n",
      "[159]\ttraining-merror:0\n",
      "[160]\ttraining-merror:0\n",
      "[161]\ttraining-merror:0\n",
      "[162]\ttraining-merror:0\n",
      "[163]\ttraining-merror:0\n",
      "[164]\ttraining-merror:0\n",
      "[165]\ttraining-merror:0\n",
      "[166]\ttraining-merror:0\n",
      "[167]\ttraining-merror:0\n",
      "[168]\ttraining-merror:0\n",
      "[169]\ttraining-merror:0\n",
      "[170]\ttraining-merror:0\n",
      "[171]\ttraining-merror:0\n",
      "[172]\ttraining-merror:0\n",
      "[173]\ttraining-merror:0\n",
      "[174]\ttraining-merror:0\n",
      "[175]\ttraining-merror:0\n",
      "[176]\ttraining-merror:0\n",
      "[177]\ttraining-merror:0\n",
      "[178]\ttraining-merror:0\n",
      "[179]\ttraining-merror:0\n",
      "[180]\ttraining-merror:0\n",
      "[181]\ttraining-merror:0\n",
      "[182]\ttraining-merror:0\n",
      "[183]\ttraining-merror:0\n",
      "[184]\ttraining-merror:0\n",
      "[185]\ttraining-merror:0\n",
      "[186]\ttraining-merror:0\n",
      "[187]\ttraining-merror:0\n",
      "[188]\ttraining-merror:0\n",
      "[189]\ttraining-merror:0\n",
      "[190]\ttraining-merror:0\n",
      "[191]\ttraining-merror:0\n",
      "[192]\ttraining-merror:0\n",
      "[193]\ttraining-merror:0\n",
      "[194]\ttraining-merror:0\n",
      "[195]\ttraining-merror:0\n",
      "[196]\ttraining-merror:0\n",
      "[197]\ttraining-merror:0\n",
      "[198]\ttraining-merror:0\n",
      "[199]\ttraining-merror:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "param = {\n",
    "    'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'multi:softprob','num_class': 3}  \n",
    "num_round = 200  \n",
    "bst = xgb.train(param, dtrain, num_round,evals=[(dtrain, \"training\")],xgb_model='m')\n",
    "# preds = bst.predict(dtest)\n",
    "\n",
    "# best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "# print(\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro') )\n",
    "\n",
    "\n",
    "# joblib.dump(bst, 'bst_modellll', compress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b'[02:20:01] src/objective/multiclass_obj.cc:75: Check failed: label_error >= 0 && label_error < nclass SoftmaxMultiClassObj: label must be in [0, num_class), num_class=2 but found 2 in label.\\n\\nStack trace returned 6 entries:\\n[bt] (0) 0   libxgboost.dylib                    0x000000011950eaa8 _ZN4dmlc15LogMessageFatalD2Ev + 40\\n[bt] (1) 1   libxgboost.dylib                    0x00000001195823b2 _ZN7xgboost3obj20SoftmaxMultiClassObj11GetGradientERKNSt3__16vectorIfNS2_9allocatorIfEEEERKNS_8MetaInfoEiPNS3_INS_6detail18bst_gpair_internalIfEENS4_ISE_EEEE + 866\\n[bt] (2) 2   libxgboost.dylib                    0x000000011950b0f6 _ZN7xgboost11LearnerImpl13UpdateOneIterEiPNS_7DMatrixE + 1014\\n[bt] (3) 3   libxgboost.dylib                    0x000000011952473f XGBoosterUpdateOneIter + 79\\n[bt] (4) 4   _ctypes.cpython-36m-darwin.so       0x00000001063a22b7 ffi_call_unix64 + 79\\n[bt] (5) 5   ???                                 0x00007fff5af2a120 0x0 + 140734719238432\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-36b69e5495b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bst_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,xgb_model='bst_model')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxgb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# joblib.dump(xgb1, 'bst_modell.pkl', compress=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: b'[02:20:01] src/objective/multiclass_obj.cc:75: Check failed: label_error >= 0 && label_error < nclass SoftmaxMultiClassObj: label must be in [0, num_class), num_class=2 but found 2 in label.\\n\\nStack trace returned 6 entries:\\n[bt] (0) 0   libxgboost.dylib                    0x000000011950eaa8 _ZN4dmlc15LogMessageFatalD2Ev + 40\\n[bt] (1) 1   libxgboost.dylib                    0x00000001195823b2 _ZN7xgboost3obj20SoftmaxMultiClassObj11GetGradientERKNSt3__16vectorIfNS2_9allocatorIfEEEERKNS_8MetaInfoEiPNS3_INS_6detail18bst_gpair_internalIfEENS4_ISE_EEEE + 866\\n[bt] (2) 2   libxgboost.dylib                    0x000000011950b0f6 _ZN7xgboost11LearnerImpl13UpdateOneIterEiPNS_7DMatrixE + 1014\\n[bt] (3) 3   libxgboost.dylib                    0x000000011952473f XGBoosterUpdateOneIter + 79\\n[bt] (4) 4   _ctypes.cpython-36m-darwin.so       0x00000001063a22b7 ffi_call_unix64 + 79\\n[bt] (5) 5   ???                                 0x00007fff5af2a120 0x0 + 140734719238432\\n'"
     ]
    }
   ],
   "source": [
    "xgb1 = joblib.load('bst_model')\n",
    "xgb.train(param, dtrain, num_round)#,xgb_model='bst_model')\n",
    "xgb1.predict(dtest)\n",
    "# joblib.dump(xgb1, 'bst_modell.pkl', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model('m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst1 = xgb.Booster({'nthread':4}) #init model\n",
    "bst1.load_model(\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.17661837e-03,   9.81285810e-01,   1.55375274e-02],\n",
       "       [  9.88355756e-01,   1.12221930e-02,   4.22023266e-04],\n",
       "       [  1.43345649e-04,   7.48549006e-04,   9.99108136e-01],\n",
       "       [  3.20864934e-03,   9.92048085e-01,   4.74324124e-03],\n",
       "       [  3.66347143e-03,   9.44292605e-01,   5.20439558e-02],\n",
       "       [  9.95423853e-01,   4.15111938e-03,   4.25041304e-04],\n",
       "       [  5.84466383e-03,   9.93089855e-01,   1.06545165e-03],\n",
       "       [  2.49230699e-03,   1.55159328e-02,   9.81991827e-01],\n",
       "       [  8.09698948e-04,   9.84133005e-01,   1.50572686e-02],\n",
       "       [  1.25375332e-03,   9.98064339e-01,   6.81873644e-04],\n",
       "       [  2.86202575e-03,   1.78176202e-02,   9.79320288e-01],\n",
       "       [  9.97244716e-01,   2.23389873e-03,   5.21345588e-04],\n",
       "       [  9.88788545e-01,   1.07892621e-02,   4.22208075e-04],\n",
       "       [  9.97340024e-01,   2.23411224e-03,   4.25859500e-04],\n",
       "       [  9.97340024e-01,   2.23411224e-03,   4.25859500e-04],\n",
       "       [  7.23340316e-04,   9.98868227e-01,   4.08486812e-04],\n",
       "       [  2.05497054e-04,   5.80913329e-04,   9.99213576e-01],\n",
       "       [  1.60516449e-03,   9.95990455e-01,   2.40439083e-03],\n",
       "       [  5.80439018e-03,   9.86246824e-01,   7.94879254e-03],\n",
       "       [  6.89183507e-05,   1.50240958e-04,   9.99780834e-01],\n",
       "       [  9.97340024e-01,   2.23411224e-03,   4.25859500e-04],\n",
       "       [  1.73566223e-03,   5.67301884e-02,   9.41534162e-01],\n",
       "       [  9.97340024e-01,   2.23411224e-03,   4.25859500e-04],\n",
       "       [  6.89183507e-05,   1.50240958e-04,   9.99780834e-01],\n",
       "       [  8.44868191e-04,   2.38833064e-03,   9.96766806e-01],\n",
       "       [  2.63996859e-04,   7.46284262e-04,   9.98989761e-01],\n",
       "       [  1.43347890e-04,   7.32954126e-04,   9.99123752e-01],\n",
       "       [  8.44868191e-04,   2.38833064e-03,   9.96766806e-01],\n",
       "       [  9.97244716e-01,   2.23389873e-03,   5.21345588e-04],\n",
       "       [  9.97340024e-01,   2.23411224e-03,   4.25859500e-04]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst1.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
