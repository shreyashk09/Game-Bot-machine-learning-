{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.models import Sequential, Layer\n",
    "from keras.layers import Dense, MaxPool2D, Dropout, Activation, Input\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras import callbacks\n",
    "from keras.layers import Flatten, LSTM\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import copy\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input::: [disp,slp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paramotion(que):\n",
    "    \n",
    "    setpara = []\n",
    "    pos1 = que.get()\n",
    "    kk=9\n",
    "    \n",
    "    while(kk):\n",
    "        pos2 = que.get()\n",
    "        y = pos2[1] - pos1[1]\n",
    "        x = pos2[0] - pos1[0]\n",
    "        disp = round(y**2 + x**2,1)\n",
    "        slp = round(math.atan2(y,x),2)\n",
    "        setpara.append([disp, slp])\n",
    "        pos1 = pos2\n",
    "        kk-=1\n",
    "    \n",
    "    return setpara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import copy\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "vrec = cv2.VideoCapture('720p.mp4',0)\n",
    "shape = [480,680]\n",
    "\n",
    "\n",
    "setpara1 = []\n",
    "setpara2 = []\n",
    "datalist1 = []\n",
    "datalist2 = []\n",
    "labellist1 = []\n",
    "labellist2 = []\n",
    "pos11 = [0,0]\n",
    "pos12 = [0,0]\n",
    "pos21 = [0,0]\n",
    "pos22 = [0,0]\n",
    "\n",
    "kkk = 20\n",
    "while(kkk):\n",
    "    kkk-=1\n",
    "    ret, scr1 = vrec.read()\n",
    "    ret , scr2 = vrec.read()       \n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret , scr1 = vrec.read()\n",
    "    ret, scr2 = vrec.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    scr1 = cv2.resize(scr1, (680,480))\n",
    "    \n",
    "    hsv = cv2.cvtColor(scr1,cv2.COLOR_BGR2HSV)\n",
    "    hsv = cv2.inRange(hsv,(0, 70, 50),(180,255,255))\n",
    "    \n",
    "    cv2.imshow('scr1',scr1)\n",
    "\n",
    "    im3, contours, newhierarchy = cv2.findContours(hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    M = cv2.moments(contours[0])\n",
    "    if(M['m00']==0):\n",
    "        continue\n",
    "    cx = float(M['m10']/M['m00'])\n",
    "    cy = float(M['m01']/M['m00'])\n",
    "#     print(cx,cy)\n",
    "    pos12 = [cx,cy]\n",
    "    if len(setpara1) == 9:\n",
    "        datalist1+=[setpara1]\n",
    "        labellist1+=[setpara1[-1]]\n",
    "#         print(\"setpara1: \",setpara1)\n",
    "#         print(\"lis1: \",labellist1)\n",
    "        setpara1 = setpara1[1:]\n",
    "    y = pos12[1] - pos11[1]\n",
    "    x = pos12[0] - pos11[0]\n",
    "    disp = round(y**2 + x**2,1)\n",
    "    slp = round(math.atan2(y,x),2)*10\n",
    "    dr=1\n",
    "    if slp<0:\n",
    "        dr=0\n",
    "    setpara1.append([disp, abs(slp), dr])\n",
    "    pos11 = pos12\n",
    "\n",
    "#     scr2 = cv2.resize(scr2, (680,480))\n",
    "#     hsv1 = cv2.cvtColor(scr2,cv2.COLOR_BGR2HSV)\n",
    "#     hsv1 = cv2.inRange(hsv1,(0, 70, 50),(180,255,255))\n",
    "    \n",
    "#     cv2.imshow('scr2',scr2)\n",
    "\n",
    "#     im2, ncontours, hierarchy = cv2.findContours(hsv1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     M = cv2.moments(ncontours[0])\n",
    "#     if(M['m00']==0):\n",
    "#         continue\n",
    "#     cx = float(M['m10']/M['m00'])\n",
    "#     cy = float(M['m01']/M['m00'])\n",
    "#     pos22 = [cx,cy]\n",
    "#     if len(setpara2) == 9:\n",
    "#         datalist2+=[setpara2]\n",
    "#         labellist2+=[setpara2[-1]]\n",
    "#         setpara2 = setpara2[1:]\n",
    "#     y = pos22[1] - pos21[1]\n",
    "#     x = pos22[0] - pos21[0]\n",
    "#     disp = round(y**2 + x**2,1)\n",
    "#     slp = round(math.atan2(y,x),2)*10\n",
    "#     setpara2.append([disp, slp])\n",
    "#     pos21 = pos22\n",
    "#         print(\"setpara2: \",setpara2)\n",
    "#     print(\"FPS: \", 1.0 / (time.time() - start_time))\n",
    "    q=cv2.waitKey(1)\n",
    "\n",
    "    if q==27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break;\n",
    "#     break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datalist1 = datalist1[:-2]\n",
    "datalist2 = datalist2[:-2]\n",
    "labellist1 = labellist1[2:]\n",
    "labellist2 = labellist2[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('pathInertiaData.csv', 'w') as writeFile1:\n",
    "    writer = csv.writer(writeFile1)\n",
    "    writer.writerows(datalist1)\n",
    "#     writer.writerows(datalist2)\n",
    "writeFile1.close()\n",
    "\n",
    "with open('pathInertiaLabel.csv', 'w') as writeFile2:\n",
    "    writer = csv.writer(writeFile2)\n",
    "    writer.writerows(labellist1)\n",
    "#     writer.writerows(labellist2)\n",
    "writeFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('pathInertiaData.csv', 'r') as readFile1:\n",
    "    reader = csv.reader(readFile1)\n",
    "    data = list(reader)\n",
    "readFile1.close()\n",
    "\n",
    "with open('pathInertiaLabel.csv', 'r') as readFile2:\n",
    "    reader = csv.reader(readFile2)\n",
    "    label = list(reader)\n",
    "readFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind in range(len(data)):\n",
    "    data[ind] = list(map(eval,data[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8759, 9, 3), (8759, 3))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.vstack(data)\n",
    "train_target = np.array(label)\n",
    "train_data.shape, train_target.shape\n",
    "train_data = train_data.reshape((-1, 9, 3))\n",
    "train_target = train_target.reshape((-1, 3))\n",
    "train_data.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 3)                 84        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(LSTM(3, input_shape=(9, 3), unroll=False, return_sequences=False))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyashkawalkar/anaconda3/lib/python3.6/site-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7007 samples, validate on 1752 samples\n",
      "Epoch 1/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 35.5212\n",
      "Epoch 00001: val_loss improved from inf to 17.08256, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 65s 9ms/step - loss: 35.5237 - val_loss: 17.0826\n",
      "Epoch 2/30\n",
      "7000/7007 [============================>.] - ETA: 0s - loss: 31.3099\n",
      "Epoch 00002: val_loss improved from 17.08256 to 14.46277, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 31.3100 - val_loss: 14.4628\n",
      "Epoch 3/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 27.5371\n",
      "Epoch 00003: val_loss improved from 14.46277 to 11.85897, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 59s 8ms/step - loss: 27.5406 - val_loss: 11.8590\n",
      "Epoch 4/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 24.2326\n",
      "Epoch 00004: val_loss improved from 11.85897 to 9.99046, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 63s 9ms/step - loss: 24.2372 - val_loss: 9.9905\n",
      "Epoch 5/30\n",
      "7002/7007 [============================>.] - ETA: 0s - loss: 21.4756\n",
      "Epoch 00005: val_loss improved from 9.99046 to 8.45572, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 60s 9ms/step - loss: 21.4720 - val_loss: 8.4557\n",
      "Epoch 6/30\n",
      "7005/7007 [============================>.] - ETA: 0s - loss: 19.0248\n",
      "Epoch 00006: val_loss improved from 8.45572 to 7.02461, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 60s 9ms/step - loss: 19.0274 - val_loss: 7.0246\n",
      "Epoch 7/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 16.8650\n",
      "Epoch 00007: val_loss improved from 7.02461 to 6.49424, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 61s 9ms/step - loss: 16.8641 - val_loss: 6.4942\n",
      "Epoch 8/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 14.9386\n",
      "Epoch 00008: val_loss improved from 6.49424 to 5.33126, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 61s 9ms/step - loss: 14.9412 - val_loss: 5.3313\n",
      "Epoch 9/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 13.2969\n",
      "Epoch 00009: val_loss improved from 5.33126 to 5.13956, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 66s 9ms/step - loss: 13.2958 - val_loss: 5.1396\n",
      "Epoch 10/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 11.8583\n",
      "Epoch 00010: val_loss improved from 5.13956 to 4.19425, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 62s 9ms/step - loss: 11.8580 - val_loss: 4.1943\n",
      "Epoch 11/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 10.6415\n",
      "Epoch 00011: val_loss improved from 4.19425 to 3.78936, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 68s 10ms/step - loss: 10.6402 - val_loss: 3.7894\n",
      "Epoch 12/30\n",
      "1261/7007 [====>.........................] - ETA: 52s - loss: 9.9820 "
     ]
    }
   ],
   "source": [
    "checkPoint = callbacks.ModelCheckpoint(filepath='pathInertia.h5', verbose=1, save_best_only=True)\n",
    "res = model.fit(train_data, train_target, nb_epoch=30, batch_size=1, verbose=1,callbacks=[checkPoint],validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"pathInertia.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(res.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(res.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(res.history['acc'], color='b', label='Training Accuracy')\n",
    "plt.plot(res.history['val_acc'], color='r', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models\n",
    "with open(\"pathInertia.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"pathInertia.h5\")\n",
    "    print(\"Model loaded from disk\")\n",
    "    loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in zip(train_data,train_target):\n",
    "    print(\"input\")\n",
    "    print(i)\n",
    "    print(\"predict::\")\n",
    "    print(j)\n",
    "    print(loaded_model.predict(np.array([i])))#np.array([[[2,1],[2,1],[2,1],[2,1],[2,1],[2,1],[2,1],[2,1],[2,1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
