{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/shreyashkawalkar/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras.models import Sequential, Layer\n",
    "from keras.layers import Dense, MaxPool2D, Dropout, Activation, Input\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras import callbacks\n",
    "from keras.layers import Flatten, LSTM\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import copy\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input::: [disp,slp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paramotion(que):\n",
    "    \n",
    "    setpara = []\n",
    "    pos1 = que.get()\n",
    "    kk=9\n",
    "    \n",
    "    while(kk):\n",
    "        pos2 = que.get()\n",
    "        y = pos2[1] - pos1[1]\n",
    "        x = pos2[0] - pos1[0]\n",
    "        disp = round(y**2 + x**2,1)\n",
    "        slp = round(math.atan2(y,x),2)\n",
    "        setpara.append([disp, slp])\n",
    "        pos1 = pos2\n",
    "        kk-=1\n",
    "    \n",
    "    return setpara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import copy\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "vrec = cv2.VideoCapture('720p.mp4',0)\n",
    "shape = [480,680]\n",
    "\n",
    "\n",
    "setpara1 = []\n",
    "setpara2 = []\n",
    "datalist1 = []\n",
    "datalist2 = []\n",
    "labellist1 = []\n",
    "labellist2 = []\n",
    "pos11 = [0,0]\n",
    "pos12 = [0,0]\n",
    "pos21 = [0,0]\n",
    "pos22 = [0,0]\n",
    "\n",
    "kkk = 20\n",
    "while(kkk):\n",
    "    kkk-=1\n",
    "    ret, scr1 = vrec.read()\n",
    "    ret , scr2 = vrec.read()       \n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret , scr1 = vrec.read()\n",
    "    ret, scr2 = vrec.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    scr1 = cv2.resize(scr1, (680,480))\n",
    "    \n",
    "    hsv = cv2.cvtColor(scr1,cv2.COLOR_BGR2HSV)\n",
    "    hsv = cv2.inRange(hsv,(0, 70, 50),(180,255,255))\n",
    "    \n",
    "    cv2.imshow('scr1',scr1)\n",
    "\n",
    "    im3, contours, newhierarchy = cv2.findContours(hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    M = cv2.moments(contours[0])\n",
    "    if(M['m00']==0):\n",
    "        continue\n",
    "    cx = float(M['m10']/M['m00'])\n",
    "    cy = float(M['m01']/M['m00'])\n",
    "#     print(cx,cy)\n",
    "    pos12 = [cx,cy]\n",
    "    if len(setpara1) == 9:\n",
    "        datalist1+=[setpara1]\n",
    "        labellist1+=[setpara1[-1]]\n",
    "#         print(\"setpara1: \",setpara1)\n",
    "#         print(\"lis1: \",labellist1)\n",
    "        setpara1 = setpara1[1:]\n",
    "    y = pos12[1] - pos11[1]\n",
    "    x = pos12[0] - pos11[0]\n",
    "    disp = round(y**2 + x**2,1)\n",
    "    slp = round(math.atan2(y,x),2)\n",
    "    setpara1.append([disp, slp])\n",
    "    pos11 = pos12\n",
    "\n",
    "    scr2 = cv2.resize(scr2, (680,480))\n",
    "    hsv1 = cv2.cvtColor(scr2,cv2.COLOR_BGR2HSV)\n",
    "    hsv1 = cv2.inRange(hsv1,(0, 70, 50),(180,255,255))\n",
    "    \n",
    "    cv2.imshow('scr2',scr2)\n",
    "\n",
    "    im2, ncontours, hierarchy = cv2.findContours(hsv1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    M = cv2.moments(ncontours[0])\n",
    "    if(M['m00']==0):\n",
    "        continue\n",
    "    cx = float(M['m10']/M['m00'])\n",
    "    cy = float(M['m01']/M['m00'])\n",
    "    pos22 = [cx,cy]\n",
    "    if len(setpara2) == 9:\n",
    "        datalist2+=[setpara2]\n",
    "        labellist2+=[setpara2[-1]]\n",
    "        setpara2 = setpara2[1:]\n",
    "    y = pos22[1] - pos21[1]\n",
    "    x = pos22[0] - pos21[0]\n",
    "    disp = round(y**2 + x**2,1)\n",
    "    slp = round(math.atan2(y,x),2)\n",
    "    setpara2.append([disp, slp])\n",
    "    pos21 = pos22\n",
    "#         print(\"setpara2: \",setpara2)\n",
    "#     print(\"FPS: \", 1.0 / (time.time() - start_time))\n",
    "    q=cv2.waitKey(1)\n",
    "\n",
    "    if q==27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break;\n",
    "#     break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datalist1 = datalist1[:-2]\n",
    "datalist2 = datalist2[:-2]\n",
    "labellist1 = labellist1[2:]\n",
    "labellist2 = labellist2[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('pathInertiaData.csv', 'w') as writeFile1:\n",
    "    writer = csv.writer(writeFile1)\n",
    "    writer.writerows(datalist1)\n",
    "    writer.writerows(datalist2)\n",
    "writeFile1.close()\n",
    "\n",
    "with open('pathInertiaLabel.csv', 'w') as writeFile2:\n",
    "    writer = csv.writer(writeFile2)\n",
    "    writer.writerows(labellist1)\n",
    "    writer.writerows(labellist2)\n",
    "writeFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6d729662e065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('pathInertiaData.csv', 'r') as readFile1:\n",
    "    reader = csv.reader(readFile1)\n",
    "    data = list(reader)\n",
    "readFile1.close()\n",
    "\n",
    "with open('pathInertiaLabel.csv', 'r') as readFile2:\n",
    "    reader = csv.reader(readFile2)\n",
    "    label = list(reader)\n",
    "readFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind in range(len(data)):\n",
    "    data[ind] = list(map(eval,data[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17517, 9, 2), (17517, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.vstack(data)\n",
    "train_target = np.array(label)\n",
    "train_data.shape, train_target.shape\n",
    "train_data = train_data.reshape((-1, 9, 2))\n",
    "train_target = train_target.reshape((-1, 2))\n",
    "train_data.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 2)                 40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 46\n",
      "Trainable params: 46\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(LSTM(2, input_shape=(9, 2), unroll=False, return_sequences=False))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyashkawalkar/anaconda3/lib/python3.6/site-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14013 samples, validate on 3504 samples\n",
      "Epoch 1/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 38.8220\n",
      "Epoch 00001: val_loss improved from inf to 45.26216, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 191s 14ms/step - loss: 38.8264 - val_loss: 45.2622\n",
      "Epoch 2/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 31.0001\n",
      "Epoch 00002: val_loss improved from 45.26216 to 36.88877, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 126s 9ms/step - loss: 31.0077 - val_loss: 36.8888\n",
      "Epoch 3/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 25.4856\n",
      "Epoch 00003: val_loss improved from 36.88877 to 30.20816, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 127s 9ms/step - loss: 25.4838 - val_loss: 30.2082\n",
      "Epoch 4/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 21.0658\n",
      "Epoch 00004: val_loss improved from 30.20816 to 25.83365, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 127s 9ms/step - loss: 21.0638 - val_loss: 25.8336\n",
      "Epoch 5/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 17.5685\n",
      "Epoch 00005: val_loss improved from 25.83365 to 20.97566, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 123s 9ms/step - loss: 17.5722 - val_loss: 20.9757\n",
      "Epoch 6/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 14.7578\n",
      "Epoch 00006: val_loss improved from 20.97566 to 17.59074, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 122s 9ms/step - loss: 14.7542 - val_loss: 17.5907\n",
      "Epoch 7/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 12.4797\n",
      "Epoch 00007: val_loss improved from 17.59074 to 14.73877, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 126s 9ms/step - loss: 12.4773 - val_loss: 14.7388\n",
      "Epoch 8/200\n",
      "14009/14013 [============================>.] - ETA: 0s - loss: 10.6428\n",
      "Epoch 00008: val_loss improved from 14.73877 to 12.62387, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 10.6427 - val_loss: 12.6239\n",
      "Epoch 9/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 13.8082\n",
      "Epoch 00009: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 13.8073 - val_loss: 21.5381\n",
      "Epoch 10/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 15.2939\n",
      "Epoch 00010: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 15.2888 - val_loss: 18.8492\n",
      "Epoch 11/200\n",
      "14006/14013 [============================>.] - ETA: 0s - loss: 13.5920\n",
      "Epoch 00011: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 13.5895 - val_loss: 16.5793\n",
      "Epoch 12/200\n",
      "14009/14013 [============================>.] - ETA: 0s - loss: 12.1649\n",
      "Epoch 00012: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 12.1643 - val_loss: 15.0920\n",
      "Epoch 13/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 10.9629\n",
      "Epoch 00013: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 10.9625 - val_loss: 13.2592\n",
      "Epoch 14/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 9.9542\n",
      "Epoch 00014: val_loss improved from 12.62387 to 12.26685, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 433s 31ms/step - loss: 9.9524 - val_loss: 12.2668\n",
      "Epoch 15/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 9.1059\n",
      "Epoch 00015: val_loss improved from 12.26685 to 11.21669, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 131s 9ms/step - loss: 9.1060 - val_loss: 11.2167\n",
      "Epoch 16/200\n",
      "14009/14013 [============================>.] - ETA: 0s - loss: 8.8012\n",
      "Epoch 00016: val_loss improved from 11.21669 to 11.19512, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 210s 15ms/step - loss: 8.8050 - val_loss: 11.1951\n",
      "Epoch 17/200\n",
      "14009/14013 [============================>.] - ETA: 0s - loss: 7.8451\n",
      "Epoch 00017: val_loss improved from 11.19512 to 9.64453, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 144s 10ms/step - loss: 7.8481 - val_loss: 9.6445\n",
      "Epoch 18/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 7.3292\n",
      "Epoch 00018: val_loss improved from 9.64453 to 8.90460, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 135s 10ms/step - loss: 7.3285 - val_loss: 8.9046\n",
      "Epoch 19/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 6.8973\n",
      "Epoch 00019: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 6.8969 - val_loss: 9.1474\n",
      "Epoch 20/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 6.5945\n",
      "Epoch 00020: val_loss improved from 8.90460 to 8.72775, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 6.5932 - val_loss: 8.7278\n",
      "Epoch 21/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 6.3312\n",
      "Epoch 00021: val_loss improved from 8.72775 to 8.48529, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 6.3303 - val_loss: 8.4853\n",
      "Epoch 22/200\n",
      "14009/14013 [============================>.] - ETA: 0s - loss: 6.9866\n",
      "Epoch 00022: val_loss improved from 8.48529 to 7.72991, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 6.9852 - val_loss: 7.7299\n",
      "Epoch 23/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 8.7109\n",
      "Epoch 00023: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 8.7135 - val_loss: 13.2116\n",
      "Epoch 24/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 9.3302\n",
      "Epoch 00024: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 9.3291 - val_loss: 11.4070\n",
      "Epoch 25/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 8.3468\n",
      "Epoch 00025: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 8.3452 - val_loss: 10.0419\n",
      "Epoch 26/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 7.5590\n",
      "Epoch 00026: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 7.5586 - val_loss: 9.4959\n",
      "Epoch 27/200\n",
      "14006/14013 [============================>.] - ETA: 0s - loss: 7.0003\n",
      "Epoch 00027: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 7.0002 - val_loss: 8.8010\n",
      "Epoch 28/200\n",
      "14006/14013 [============================>.] - ETA: 0s - loss: 6.5419\n",
      "Epoch 00028: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 6.5422 - val_loss: 8.9221\n",
      "Epoch 29/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 7.0763\n",
      "Epoch 00029: val_loss did not improve\n",
      "14013/14013 [==============================] - 115s 8ms/step - loss: 7.0759 - val_loss: 7.9720\n",
      "Epoch 30/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 6.1537\n",
      "Epoch 00030: val_loss did not improve\n",
      "14013/14013 [==============================] - 121s 9ms/step - loss: 6.1545 - val_loss: 7.9053\n",
      "Epoch 31/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 7.2647\n",
      "Epoch 00031: val_loss improved from 7.72991 to 7.38268, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 130s 9ms/step - loss: 7.2642 - val_loss: 7.3827\n",
      "Epoch 32/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 6.1303\n",
      "Epoch 00032: val_loss did not improve\n",
      "14013/14013 [==============================] - 124s 9ms/step - loss: 6.1414 - val_loss: 24.4398\n",
      "Epoch 33/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 6.2067\n",
      "Epoch 00033: val_loss improved from 7.38268 to 7.07645, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 124s 9ms/step - loss: 6.2057 - val_loss: 7.0765\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14006/14013 [============================>.] - ETA: 0s - loss: 5.5709\n",
      "Epoch 00034: val_loss did not improve\n",
      "14013/14013 [==============================] - 131s 9ms/step - loss: 5.5732 - val_loss: 7.3365\n",
      "Epoch 35/200\n",
      "14009/14013 [============================>.] - ETA: 0s - loss: 5.8602\n",
      "Epoch 00035: val_loss did not improve\n",
      "14013/14013 [==============================] - 121s 9ms/step - loss: 5.8596 - val_loss: 7.1900\n",
      "Epoch 36/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 5.6754\n",
      "Epoch 00036: val_loss did not improve\n",
      "14013/14013 [==============================] - 130s 9ms/step - loss: 5.6748 - val_loss: 7.1554\n",
      "Epoch 37/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 5.6555\n",
      "Epoch 00037: val_loss did not improve\n",
      "14013/14013 [==============================] - 134s 10ms/step - loss: 5.6549 - val_loss: 8.3666\n",
      "Epoch 38/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 5.6053\n",
      "Epoch 00038: val_loss did not improve\n",
      "14013/14013 [==============================] - 129s 9ms/step - loss: 5.6048 - val_loss: 7.2131\n",
      "Epoch 39/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 5.5243\n",
      "Epoch 00039: val_loss improved from 7.07645 to 6.88331, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 127s 9ms/step - loss: 5.5245 - val_loss: 6.8833\n",
      "Epoch 40/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 5.4936\n",
      "Epoch 00040: val_loss did not improve\n",
      "14013/14013 [==============================] - 122s 9ms/step - loss: 5.4943 - val_loss: 7.8369\n",
      "Epoch 41/200\n",
      "14011/14013 [============================>.] - ETA: 0s - loss: 6.2063\n",
      "Epoch 00041: val_loss did not improve\n",
      "14013/14013 [==============================] - 120s 9ms/step - loss: 6.2070 - val_loss: 8.3667\n",
      "Epoch 42/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 13.4653\n",
      "Epoch 00042: val_loss improved from 6.88331 to 6.21509, saving model to pathInertia.h5\n",
      "14013/14013 [==============================] - 120s 9ms/step - loss: 13.4616 - val_loss: 6.2151\n",
      "Epoch 43/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 5.5464\n",
      "Epoch 00043: val_loss did not improve\n",
      "14013/14013 [==============================] - 127s 9ms/step - loss: 5.5460 - val_loss: 10.7863\n",
      "Epoch 44/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 7.2445\n",
      "Epoch 00044: val_loss did not improve\n",
      "14013/14013 [==============================] - 138s 10ms/step - loss: 7.2442 - val_loss: 6.7422\n",
      "Epoch 45/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 5.4212\n",
      "Epoch 00045: val_loss did not improve\n",
      "14013/14013 [==============================] - 135s 10ms/step - loss: 5.4229 - val_loss: 6.6166\n",
      "Epoch 46/200\n",
      "14006/14013 [============================>.] - ETA: 0s - loss: 5.5121\n",
      "Epoch 00046: val_loss did not improve\n",
      "14013/14013 [==============================] - 136s 10ms/step - loss: 5.5125 - val_loss: 7.5827\n",
      "Epoch 47/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 9.5243\n",
      "Epoch 00047: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 9.5227 - val_loss: 7.1506\n",
      "Epoch 48/200\n",
      "14006/14013 [============================>.] - ETA: 0s - loss: 6.4823\n",
      "Epoch 00048: val_loss did not improve\n",
      "14013/14013 [==============================] - 128s 9ms/step - loss: 6.4840 - val_loss: 9.0873\n",
      "Epoch 49/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 7.3220\n",
      "Epoch 00049: val_loss did not improve\n",
      "14013/14013 [==============================] - 123s 9ms/step - loss: 7.3199 - val_loss: 6.9345\n",
      "Epoch 50/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 7.1481\n",
      "Epoch 00050: val_loss did not improve\n",
      "14013/14013 [==============================] - 133s 9ms/step - loss: 7.1508 - val_loss: 39.2510\n",
      "Epoch 51/200\n",
      "14007/14013 [============================>.] - ETA: 0s - loss: 7.8207\n",
      "Epoch 00051: val_loss did not improve\n",
      "14013/14013 [==============================] - 135s 10ms/step - loss: 7.8210 - val_loss: 6.6773\n",
      "Epoch 52/200\n",
      "14010/14013 [============================>.] - ETA: 0s - loss: 8.6759\n",
      "Epoch 00052: val_loss did not improve\n",
      "14013/14013 [==============================] - 132s 9ms/step - loss: 8.6757 - val_loss: 16.2350\n",
      "Epoch 53/200\n",
      "14012/14013 [============================>.] - ETA: 0s - loss: 6.0998\n",
      "Epoch 00053: val_loss did not improve\n",
      "14013/14013 [==============================] - 131s 9ms/step - loss: 6.0995 - val_loss: 7.0489\n",
      "Epoch 54/200\n",
      "14008/14013 [============================>.] - ETA: 0s - loss: 5.7283\n",
      "Epoch 00054: val_loss did not improve\n",
      "14013/14013 [==============================] - 131s 9ms/step - loss: 5.7283 - val_loss: 6.5089\n",
      "Epoch 55/200\n",
      " 7746/14013 [===============>..............] - ETA: 57s - loss: 5.4609"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-29efb0606759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckPoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pathInertia.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckPoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pathInertia.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkPoint = callbacks.ModelCheckpoint(filepath='pathInertia.h5', verbose=1, save_best_only=True)\n",
    "model.fit(train_data, train_target, nb_epoch=200, batch_size=1, verbose=1,callbacks=[checkPoint],validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"pathInertia.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
