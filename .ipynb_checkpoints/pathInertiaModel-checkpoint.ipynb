{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.models import Sequential, Layer\n",
    "from keras.layers import Dense, MaxPool2D, Dropout, Activation, Input\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras import callbacks\n",
    "from keras.layers import Flatten, LSTM\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import copy\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input::: [disp,slp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paramotion(que):\n",
    "    \n",
    "    setpara = []\n",
    "    pos1 = que.get()\n",
    "    kk=9\n",
    "    \n",
    "    while(kk):\n",
    "        pos2 = que.get()\n",
    "        y = pos2[1] - pos1[1]\n",
    "        x = pos2[0] - pos1[0]\n",
    "        disp = round(y**2 + x**2,1)\n",
    "        slp = round(math.atan2(y,x),2)\n",
    "        setpara.append([disp, slp])\n",
    "        pos1 = pos2\n",
    "        kk-=1\n",
    "    \n",
    "    return setpara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import queue\n",
    "import copy\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "vrec = cv2.VideoCapture('720p.mp4',0)\n",
    "shape = [480,680]\n",
    "\n",
    "\n",
    "setpara1 = []\n",
    "setpara2 = []\n",
    "datalist1 = []\n",
    "datalist2 = []\n",
    "labellist1 = []\n",
    "labellist2 = []\n",
    "pos11 = [0,0]\n",
    "pos12 = [0,0]\n",
    "pos21 = [0,0]\n",
    "pos22 = [0,0]\n",
    "\n",
    "kkk = 20\n",
    "while(kkk):\n",
    "    kkk-=1\n",
    "    ret, scr1 = vrec.read()\n",
    "    ret , scr2 = vrec.read()       \n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret , scr1 = vrec.read()\n",
    "    ret, scr2 = vrec.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    scr1 = cv2.resize(scr1, (680,480))\n",
    "    \n",
    "    hsv = cv2.cvtColor(scr1,cv2.COLOR_BGR2HSV)\n",
    "    hsv = cv2.inRange(hsv,(0, 70, 50),(180,255,255))\n",
    "    \n",
    "    cv2.imshow('scr1',scr1)\n",
    "\n",
    "    im3, contours, newhierarchy = cv2.findContours(hsv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    M = cv2.moments(contours[0])\n",
    "    if(M['m00']==0):\n",
    "        continue\n",
    "    cx = float(M['m10']/M['m00'])\n",
    "    cy = float(M['m01']/M['m00'])\n",
    "#     print(cx,cy)\n",
    "    pos12 = [cx,cy]\n",
    "    if len(setpara1) == 9:\n",
    "        datalist1+=[setpara1]\n",
    "        labellist1+=[setpara1[-1]]\n",
    "#         print(\"setpara1: \",setpara1)\n",
    "#         print(\"lis1: \",labellist1)\n",
    "        setpara1 = setpara1[1:]\n",
    "    y = pos12[1] - pos11[1]\n",
    "    x = pos12[0] - pos11[0]\n",
    "    disp = round(y**2 + x**2,1)\n",
    "    slp = round(math.atan2(y,x),2)*10\n",
    "    dr=1\n",
    "    if slp<0:\n",
    "        dr=0\n",
    "    setpara1.append([disp, abs(slp), dr])\n",
    "    pos11 = pos12\n",
    "\n",
    "#     scr2 = cv2.resize(scr2, (680,480))\n",
    "#     hsv1 = cv2.cvtColor(scr2,cv2.COLOR_BGR2HSV)\n",
    "#     hsv1 = cv2.inRange(hsv1,(0, 70, 50),(180,255,255))\n",
    "    \n",
    "#     cv2.imshow('scr2',scr2)\n",
    "\n",
    "#     im2, ncontours, hierarchy = cv2.findContours(hsv1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     M = cv2.moments(ncontours[0])\n",
    "#     if(M['m00']==0):\n",
    "#         continue\n",
    "#     cx = float(M['m10']/M['m00'])\n",
    "#     cy = float(M['m01']/M['m00'])\n",
    "#     pos22 = [cx,cy]\n",
    "#     if len(setpara2) == 9:\n",
    "#         datalist2+=[setpara2]\n",
    "#         labellist2+=[setpara2[-1]]\n",
    "#         setpara2 = setpara2[1:]\n",
    "#     y = pos22[1] - pos21[1]\n",
    "#     x = pos22[0] - pos21[0]\n",
    "#     disp = round(y**2 + x**2,1)\n",
    "#     slp = round(math.atan2(y,x),2)*10\n",
    "#     setpara2.append([disp, slp])\n",
    "#     pos21 = pos22\n",
    "#         print(\"setpara2: \",setpara2)\n",
    "#     print(\"FPS: \", 1.0 / (time.time() - start_time))\n",
    "    q=cv2.waitKey(1)\n",
    "\n",
    "    if q==27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break;\n",
    "#     break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datalist1 = datalist1[:-2]\n",
    "datalist2 = datalist2[:-2]\n",
    "labellist1 = labellist1[2:]\n",
    "labellist2 = labellist2[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('pathInertiaData.csv', 'w') as writeFile1:\n",
    "    writer = csv.writer(writeFile1)\n",
    "    writer.writerows(datalist1)\n",
    "#     writer.writerows(datalist2)\n",
    "writeFile1.close()\n",
    "\n",
    "with open('pathInertiaLabel.csv', 'w') as writeFile2:\n",
    "    writer = csv.writer(writeFile2)\n",
    "    writer.writerows(labellist1)\n",
    "#     writer.writerows(labellist2)\n",
    "writeFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('pathInertiaData.csv', 'r') as readFile1:\n",
    "    reader = csv.reader(readFile1)\n",
    "    data = list(reader)\n",
    "readFile1.close()\n",
    "\n",
    "with open('pathInertiaLabel.csv', 'r') as readFile2:\n",
    "    reader = csv.reader(readFile2)\n",
    "    label = list(reader)\n",
    "readFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind in range(len(data)):\n",
    "    data[ind] = list(map(eval,data[ind])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8759, 9, 3), (8759, 3))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.vstack(data)\n",
    "train_target = np.array(label)\n",
    "train_data.shape, train_target.shape\n",
    "train_data = train_data.reshape((-1, 9, 3))\n",
    "train_target = train_target.reshape((-1, 3))\n",
    "train_data.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 3)                 84        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(LSTM(3, input_shape=(9, 3), unroll=False, return_sequences=False))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyashkawalkar/anaconda3/lib/python3.6/site-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7007 samples, validate on 1752 samples\n",
      "Epoch 1/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 35.5212\n",
      "Epoch 00001: val_loss improved from inf to 17.08256, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 65s 9ms/step - loss: 35.5237 - val_loss: 17.0826\n",
      "Epoch 2/30\n",
      "7000/7007 [============================>.] - ETA: 0s - loss: 31.3099\n",
      "Epoch 00002: val_loss improved from 17.08256 to 14.46277, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 31.3100 - val_loss: 14.4628\n",
      "Epoch 3/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 27.5371\n",
      "Epoch 00003: val_loss improved from 14.46277 to 11.85897, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 59s 8ms/step - loss: 27.5406 - val_loss: 11.8590\n",
      "Epoch 4/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 24.2326\n",
      "Epoch 00004: val_loss improved from 11.85897 to 9.99046, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 63s 9ms/step - loss: 24.2372 - val_loss: 9.9905\n",
      "Epoch 5/30\n",
      "7002/7007 [============================>.] - ETA: 0s - loss: 21.4756\n",
      "Epoch 00005: val_loss improved from 9.99046 to 8.45572, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 60s 9ms/step - loss: 21.4720 - val_loss: 8.4557\n",
      "Epoch 6/30\n",
      "7005/7007 [============================>.] - ETA: 0s - loss: 19.0248\n",
      "Epoch 00006: val_loss improved from 8.45572 to 7.02461, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 60s 9ms/step - loss: 19.0274 - val_loss: 7.0246\n",
      "Epoch 7/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 16.8650\n",
      "Epoch 00007: val_loss improved from 7.02461 to 6.49424, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 61s 9ms/step - loss: 16.8641 - val_loss: 6.4942\n",
      "Epoch 8/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 14.9386\n",
      "Epoch 00008: val_loss improved from 6.49424 to 5.33126, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 61s 9ms/step - loss: 14.9412 - val_loss: 5.3313\n",
      "Epoch 9/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 13.2969\n",
      "Epoch 00009: val_loss improved from 5.33126 to 5.13956, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 66s 9ms/step - loss: 13.2958 - val_loss: 5.1396\n",
      "Epoch 10/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 11.8583\n",
      "Epoch 00010: val_loss improved from 5.13956 to 4.19425, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 62s 9ms/step - loss: 11.8580 - val_loss: 4.1943\n",
      "Epoch 11/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 10.6415\n",
      "Epoch 00011: val_loss improved from 4.19425 to 3.78936, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 68s 10ms/step - loss: 10.6402 - val_loss: 3.7894\n",
      "Epoch 12/30\n",
      "7003/7007 [============================>.] - ETA: 0s - loss: 9.6708\n",
      "Epoch 00012: val_loss did not improve\n",
      "7007/7007 [==============================] - 65s 9ms/step - loss: 9.6738 - val_loss: 3.8201\n",
      "Epoch 13/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 8.8663\n",
      "Epoch 00013: val_loss improved from 3.78936 to 3.66775, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 8.8620 - val_loss: 3.6678\n",
      "Epoch 14/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 8.2223\n",
      "Epoch 00014: val_loss did not improve\n",
      "7007/7007 [==============================] - 57s 8ms/step - loss: 8.2219 - val_loss: 3.7256\n",
      "Epoch 15/30\n",
      "7002/7007 [============================>.] - ETA: 0s - loss: 7.7416\n",
      "Epoch 00015: val_loss did not improve\n",
      "7007/7007 [==============================] - 60s 9ms/step - loss: 7.7434 - val_loss: 3.9942\n",
      "Epoch 16/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 7.3231\n",
      "Epoch 00016: val_loss improved from 3.66775 to 3.45482, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 7.3225 - val_loss: 3.4548\n",
      "Epoch 17/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 7.0405\n",
      "Epoch 00017: val_loss did not improve\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 7.0376 - val_loss: 3.5807\n",
      "Epoch 18/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 6.7630\n",
      "Epoch 00018: val_loss did not improve\n",
      "7007/7007 [==============================] - 82s 12ms/step - loss: 6.7636 - val_loss: 3.7501\n",
      "Epoch 19/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 6.5728\n",
      "Epoch 00019: val_loss did not improve\n",
      "7007/7007 [==============================] - 769s 110ms/step - loss: 6.5752 - val_loss: 3.8902\n",
      "Epoch 20/30\n",
      "7002/7007 [============================>.] - ETA: 0s - loss: 6.3736\n",
      "Epoch 00020: val_loss did not improve\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 6.3749 - val_loss: 4.8084\n",
      "Epoch 21/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 6.3579\n",
      "Epoch 00021: val_loss did not improve\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 6.3582 - val_loss: 4.2087\n",
      "Epoch 22/30\n",
      "7005/7007 [============================>.] - ETA: 0s - loss: 6.3368\n",
      "Epoch 00022: val_loss did not improve\n",
      "7007/7007 [==============================] - 58s 8ms/step - loss: 6.3363 - val_loss: 4.0007\n",
      "Epoch 23/30\n",
      "7006/7007 [============================>.] - ETA: 0s - loss: 6.1698\n",
      "Epoch 00023: val_loss did not improve\n",
      "7007/7007 [==============================] - 791s 113ms/step - loss: 6.1696 - val_loss: 4.1089\n",
      "Epoch 24/30\n",
      "7002/7007 [============================>.] - ETA: 0s - loss: 6.3835\n",
      "Epoch 00024: val_loss did not improve\n",
      "7007/7007 [==============================] - 63s 9ms/step - loss: 6.3835 - val_loss: 4.0208\n",
      "Epoch 25/30\n",
      "7002/7007 [============================>.] - ETA: 0s - loss: 6.8557\n",
      "Epoch 00025: val_loss did not improve\n",
      "7007/7007 [==============================] - 60s 9ms/step - loss: 6.8561 - val_loss: 5.5155\n",
      "Epoch 26/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 6.1322\n",
      "Epoch 00026: val_loss did not improve\n",
      "7007/7007 [==============================] - 61s 9ms/step - loss: 6.1317 - val_loss: 4.1084\n",
      "Epoch 27/30\n",
      "7004/7007 [============================>.] - ETA: 0s - loss: 6.1634\n",
      "Epoch 00027: val_loss did not improve\n",
      "7007/7007 [==============================] - 62s 9ms/step - loss: 6.1681 - val_loss: 3.7164\n",
      "Epoch 28/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 6.1599\n",
      "Epoch 00028: val_loss improved from 3.45482 to 3.44614, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 65s 9ms/step - loss: 6.1580 - val_loss: 3.4461\n",
      "Epoch 29/30\n",
      "7003/7007 [============================>.] - ETA: 0s - loss: 5.5751\n",
      "Epoch 00029: val_loss did not improve\n",
      "7007/7007 [==============================] - 63s 9ms/step - loss: 5.5864 - val_loss: 4.5833\n",
      "Epoch 30/30\n",
      "7001/7007 [============================>.] - ETA: 0s - loss: 5.8354\n",
      "Epoch 00030: val_loss improved from 3.44614 to 3.29157, saving model to pathInertia.h5\n",
      "7007/7007 [==============================] - 63s 9ms/step - loss: 5.8343 - val_loss: 3.2916\n"
     ]
    }
   ],
   "source": [
    "checkPoint = callbacks.ModelCheckpoint(filepath='pathInertia.h5', verbose=1, save_best_only=True)\n",
    "res = model.fit(train_data, train_target, nb_epoch=30, batch_size=1, verbose=1,callbacks=[checkPoint],validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"pathInertia.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAADYCAYAAAAkl0i1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREpaApFIiIiIiJS0BSKRERERESkoP1/ELIDRwvACDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(14,3))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(res.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(res.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.ylabel('Accuracy', fontsize=16)\n",
    "# plt.plot(res.history['acc'], color='b', label='Training Accuracy')\n",
    "# plt.plot(res.history['val_acc'], color='r', label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models\n",
    "with open(\"pathInertia.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"pathInertia.h5\")\n",
    "    print(\"Model loaded from disk\")\n",
    "    loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in zip(train_data,train_target):\n",
    "    print(\"input\")\n",
    "    print(i)\n",
    "    print(\"predict::\")\n",
    "    print(j)\n",
    "    print(loaded_model.predict(np.array([i])))#np.array([[[2,1],[2,1],[2,1],[2,1],[2,1],[2,1],[2,1],[2,1],[2,1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
